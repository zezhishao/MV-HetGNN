from abc import ABC
import torch
import torch.nn as nn

class EgoGraphEncoding(nn.Module, ABC):
    def __init__(self, metapath):
        r"""
        Encode metapath based ego network with an multi-layer feed-forward bottom-up structure.
        
        Args:
            - metapath: The corresponding metapath of the ego network.
        
        Returns:
            - Representations of target nodes under the semantic `metapath`.
        """
        super(EgoGraphEncoding, self).__init__()
        self.metapath = metapath

    def forward(self, hierarchical_relational_graphs, edge_types, relational_encoders, transformed_features,
                feature_index):
        r"""
        Args:
            - hierarchical_relational_graphs: hierarchical relational graphs of this metapath.
                For example: 
                    APA contains hierarchical relational graphs: AP and PA.
                    src nodes in this graph is the lower level nodes.
                    dsr nodes in this graph is the upper level nodes.
            - edge_types: edge types for selecting relational encoders. e.g. AP=0 PA=1
            - relational_encoders: encoders to conduct message passing to encode the relational graphs.
            - transformed_features: features generated by structure-aware node transformation.
            - feature_index: feature index in transformed features of each hierarchical relational graphs.
        """
        src_data = None
        for i, relation in enumerate(edge_types):
            graph = hierarchical_relational_graphs[i]
            _feature_index   = feature_index[i]

            src_ids_on_graph = feature_index[i]['src_ids_on_graph']
            dst_ids_on_graph = feature_index[i]['dst_ids_on_graph']

            src_ids_original = feature_index[i]['src_ids_original']
            dst_ids_original = feature_index[i]['dst_ids_original']

            if src_data is None:
                src_data = transformed_features[src_ids_original.type(torch.int64)]
            dst_data    = transformed_features[dst_ids_original.type(torch.int64)]

            updated_h   = relational_encoders[relation](graph, src_data, dst_data, src_ids_on_graph, dst_ids_on_graph)
            src_data    = updated_h

        src_data = src_data / (len(edge_types) + 1)
        return src_data


class CompGCNEncoder(nn.Module, ABC):
    def __init__(self, comp_vec, gcn_encoder):
        """
        Args:
            - comp_vec: The representations of relation.
            - gcn_encoder: Graphconv for one step message passsing.
        """
        super(CompGCNEncoder, self).__init__()
        # =============== network information ================= #
        self.comp_vec       = comp_vec
        self.gcn_encoder    = gcn_encoder

        self.activation     = nn.ReLU()
        self.dropout        = torch.nn.Dropout(0.3)

    def phi(self, h_s, h_r):
        return h_s + h_r

    def forward(self, graph, src_data, dst_data, src_ids_on_graph, dst_ids_on_graph, top=False):
        """
        Top: 是否是最高层。
        """
        # ====================== get hierarchical graph ================== #
        src_data        = self.phi(src_data, self.comp_vec)
        dst_zeros_data  = torch.zeros_like(dst_data)

        feat    = torch.cat([src_data, dst_zeros_data])
        ids     = torch.cat([src_ids_on_graph, dst_ids_on_graph])
        graph.nodes[ids].data['feat'] = feat
        feat    = graph.ndata.pop('feat')

        # dst_zeros_data has been set to zero, therefore the `add_self_loop` will not cause an error.
        graph   = graph.add_self_loop()

        # ================== message passing =================== #
        encoded_data        = self.gcn_encoder(graph, feat)  # num_nodes x hidden_dims

        encoded_neighbors   = encoded_data[dst_ids_on_graph]

        encoded_neighbors   = self.activation(encoded_neighbors)
        
        updated_result      = dst_data + encoded_neighbors

        updated_result      = self.dropout(updated_result)

        return updated_result
